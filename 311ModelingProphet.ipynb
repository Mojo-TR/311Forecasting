{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf201de5-9cd2-4046-989b-82245edc5963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:21:04.758767Z",
     "start_time": "2025-11-13T20:21:04.753710Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mojo/Documents/MyProjects/311Detector/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.getenv(\"DATABASE_URL\")\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4a683b-57e6-4bcf-8dd1-98efd6ec89d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:13:27.970733Z",
     "start_time": "2025-11-13T20:13:21.706692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to your Postgres database\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Load the table into a DataFrame\n",
    "df = pd.read_sql(\"SELECT * FROM houston_311\", engine)\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab3bd4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:13:36.416154Z",
     "start_time": "2025-11-13T20:13:36.405670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                    CASE NUMBER                                 NEIGHBORHOOD  \\\n",
       "0        12091834-101002444724                 EAST LITTLE YORK / HOMESTEAD   \n",
       "1        12091835-101002444725                          NORTHSIDE/NORTHLINE   \n",
       "2                 101002444726                                     MID WEST   \n",
       "3                 101002444727  WASHINGTON AVENUE COALITION / MEMORIAL PARK   \n",
       "4        12091836-101002444730                               GREATER UPTOWN   \n",
       "...                        ...                                          ...   \n",
       "3800664      217348-2400490914                                     WESTBURY   \n",
       "3800665    12670427-2400490912                    GREATER OST / SOUTH UNION   \n",
       "3800666             2400490911                                        ALIEF   \n",
       "3800667    20480340-2400490910                                   NORTHSHORE   \n",
       "3800668    12670426-2400490909                          NORTHSIDE/NORTHLINE   \n",
       "\n",
       "                     DEPARTMENT                            DIVISION  \\\n",
       "0                  Public Works                       Houston Water   \n",
       "1                  Public Works                       Houston Water   \n",
       "2                  Public Works  Transportation Drainage Operations   \n",
       "3                  Public Works        Capitol Improvement Planning   \n",
       "4                  Public Works                       Houston Water   \n",
       "...                         ...                                 ...   \n",
       "3800664    Parks and Recreation                            Forestry   \n",
       "3800665            Public Works  Transportation Drainage Operations   \n",
       "3800666  Solid Waste Management                           Recycling   \n",
       "3800667            Public Works                       Houston Water   \n",
       "3800668            Public Works  Transportation Drainage Operations   \n",
       "\n",
       "                                  CASE TYPE        CREATED DATE  \\\n",
       "0                              Fire Hydrant 2017-01-01 00:01:48   \n",
       "1                              Fire Hydrant 2017-01-01 00:07:29   \n",
       "2                Traffic Signal Maintenance 2017-01-01 00:14:04   \n",
       "3        MultiFamily Habitability Violation 2017-01-01 00:17:23   \n",
       "4                                Water Leak 2017-01-01 00:30:48   \n",
       "...                                     ...                 ...   \n",
       "3800664                           Tree Trim 2024-12-01 04:37:44   \n",
       "3800665          Traffic Signal Maintenance 2024-12-01 04:19:45   \n",
       "3800666             Missed Recycling Pickup 2024-12-01 03:30:54   \n",
       "3800667                          Water Leak 2024-12-01 03:17:53   \n",
       "3800668          Traffic Signal Maintenance 2024-12-01 02:54:09   \n",
       "\n",
       "                CLOSED DATE  LATITUDE  LONGITUDE  \\\n",
       "0       2017-01-01 11:20:02     29.86     -95.30   \n",
       "1       2017-01-01 04:50:02     29.83     -95.37   \n",
       "2       2017-01-01 00:23:57     29.72     -95.54   \n",
       "3       2017-01-04 14:01:37     29.77     -95.40   \n",
       "4       2017-02-02 13:20:06     29.73     -95.47   \n",
       "...                     ...       ...        ...   \n",
       "3800664 2025-05-29 09:29:00     29.65     -95.48   \n",
       "3800665 2024-12-17 07:13:00     29.70     -95.33   \n",
       "3800666 2024-12-11 09:17:00     29.71     -95.59   \n",
       "3800667 2024-12-01 10:28:00     29.78     -95.23   \n",
       "3800668 2024-12-01 05:25:00     29.84     -95.38   \n",
       "\n",
       "                                    CATEGORY  RESOLUTION_TIME_DAYS  \n",
       "0        Public Infrastructure / Engineering                  0.00  \n",
       "1        Public Infrastructure / Engineering                  0.00  \n",
       "2                    Traffic Signals & Signs                  0.00  \n",
       "3                    Public Health & Housing                  4.00  \n",
       "4                      Water Service & Leaks                 33.00  \n",
       "...                                      ...                   ...  \n",
       "3800664                     Trees & Forestry                179.00  \n",
       "3800665              Traffic Signals & Signs                 16.00  \n",
       "3800666                    Trash & Recycling                 10.00  \n",
       "3800667                Water Service & Leaks                  0.00  \n",
       "3800668              Traffic Signals & Signs                  0.00  \n",
       "\n",
       "[3800669 rows x 11 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdffd58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:13:57.107170Z",
     "start_time": "2025-11-13T20:13:57.092499Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22550d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE NUMBER</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>CASE TYPE</th>\n",
       "      <th>CREATED DATE</th>\n",
       "      <th>CLOSED DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>RESOLUTION_TIME_DAYS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CASE NUMBER, NEIGHBORHOOD, DEPARTMENT, DIVISION, CASE TYPE, CREATED DATE, CLOSED DATE, LATITUDE, LONGITUDE, CATEGORY, RESOLUTION_TIME_DAYS]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"CREATED DATE\"] > pd.Timestamp.today()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d529745",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"NEIGHBORHOOD\", \"DEPARTMENT\", \"DIVISION\", \"CATEGORY\", \"CASE TYPE\"]\n",
    "\n",
    "for c in cols:\n",
    "    df[c] = (\n",
    "        df[c]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.title()\n",
    "        .str.replace(\"\\s+\", \" \", regex=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fedee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:14:21.640868Z",
     "start_time": "2025-11-13T20:14:21.000943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate by month\n",
    "overall_ts = (\n",
    "    df.groupby(pd.Grouper(key='CREATED DATE', freq='ME'))\n",
    "      .size()\n",
    "      .reset_index(name='y')\n",
    "      .rename(columns={'CREATED DATE': 'ds'})\n",
    ")\n",
    "\n",
    "# Remove months with too few rows\n",
    "cleaned_ts = overall_ts[overall_ts[\"y\"] > 1000] \n",
    "\n",
    "# Determine the last fully complete month\n",
    "last_month = cleaned_ts['ds'].max()\n",
    "cleaned_ts = cleaned_ts[cleaned_ts['ds'] < last_month]\n",
    "\n",
    "# Fit Prophet\n",
    "m = Prophet(interval_width=0.95, daily_seasonality=True)\n",
    "m.fit(cleaned_ts)\n",
    "\n",
    "# Forecast next 12 months\n",
    "future = m.make_future_dataframe(periods=12, freq='ME')\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1675291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:08.688573Z",
     "start_time": "2025-11-13T20:15:08.336306Z"
    }
   },
   "outputs": [],
   "source": [
    "plot1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8e453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:14.360220Z",
     "start_time": "2025-11-13T20:15:13.983406Z"
    }
   },
   "outputs": [],
   "source": [
    "plot2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f99943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:18.361048Z",
     "start_time": "2025-11-13T20:15:18.354294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge forecasted values with actuals\n",
    "results = cleaned_ts.merge(forecast, on='ds', how='left')\n",
    "\n",
    "# Keep only training portion (historical)\n",
    "historical = results[results['ds'] <= cleaned_ts['ds'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98369471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:20.165361Z",
     "start_time": "2025-11-13T20:15:20.155554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "y_true = historical['y']\n",
    "y_pred = historical['yhat']\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6b090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:22.977218Z",
     "start_time": "2025-11-13T20:15:22.965935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only periods that exist in your original data\n",
    "actual = cleaned_ts.set_index(\"ds\")\n",
    "predicted = forecast.set_index(\"ds\")[[\"yhat\", \"yhat_lower\", \"yhat_upper\"]]\n",
    "\n",
    "# Join actuals with predictions\n",
    "compare = actual.join(predicted, how=\"left\")\n",
    "\n",
    "# Compute residuals (errors)\n",
    "compare[\"error\"] = compare[\"y\"] - compare[\"yhat\"]\n",
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b08bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:34.749433Z",
     "start_time": "2025-11-13T20:15:34.746078Z"
    }
   },
   "outputs": [],
   "source": [
    "bias = compare[\"error\"].mean()\n",
    "print(\"Mean Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e8e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:37.329500Z",
     "start_time": "2025-11-13T20:15:37.321873Z"
    }
   },
   "outputs": [],
   "source": [
    "compare[\"month\"] = compare.index.month\n",
    "monthly_bias = compare.groupby(\"month\")[\"error\"].mean()\n",
    "print(monthly_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb090053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:15:46.477871Z",
     "start_time": "2025-11-13T20:15:39.595649Z"
    }
   },
   "outputs": [],
   "source": [
    "category_col = \"NEIGHBORHOOD\"\n",
    "date_col = \"CREATED DATE\"  \n",
    "\n",
    "results = []\n",
    "\n",
    "for cat, group in df.groupby(category_col, observed=True):\n",
    "    ts = (\n",
    "        group.groupby(pd.Grouper(key=date_col, freq=\"ME\"))\n",
    "             .size()\n",
    "             .reset_index(name=\"y\")\n",
    "             .rename(columns={date_col: \"ds\"})\n",
    "             .sort_values(\"ds\")\n",
    "    )\n",
    "    \n",
    "    # Exclude last incomplete month\n",
    "    if not ts.empty:\n",
    "        last_month = ts['ds'].max()\n",
    "        ts = ts[ts['ds'] < last_month]\n",
    "    \n",
    "    # Skip if too few data points\n",
    "    if len(ts) < 24:\n",
    "        continue\n",
    "\n",
    "    # Train-test split\n",
    "    train = ts[:-6]\n",
    "    test = ts[-6:]\n",
    "    \n",
    "    # Fit Prophet\n",
    "    m = Prophet()\n",
    "    m.fit(train)\n",
    "    \n",
    "    # Make future and predict for test dates\n",
    "    future = m.make_future_dataframe(periods=6, freq=\"ME\")\n",
    "    forecast = m.predict(future)\n",
    "    forecast_test = forecast.tail(6).copy()\n",
    "    forecast_test[\"y_true\"] = test[\"y\"].values\n",
    "    \n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"])\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"]))\n",
    "    mape = np.mean(np.abs((forecast_test[\"y_true\"] - forecast_test[\"yhat\"]) / forecast_test[\"y_true\"])) * 100\n",
    "    \n",
    "    results.append({\n",
    "        \"Category\": cat,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE (%)\": mape\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(\"MAPE (%)\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4840d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:43:15.088440Z",
     "start_time": "2025-11-13T20:43:11.856095Z"
    }
   },
   "outputs": [],
   "source": [
    "category_col = \"DEPARTMENT\" \n",
    "date_col = \"CREATED DATE\"     \n",
    "\n",
    "results = []\n",
    "\n",
    "for cat, group in df.groupby(category_col, observed=True):\n",
    "    ts = (\n",
    "        group.groupby(pd.Grouper(key=date_col, freq=\"ME\"))\n",
    "             .size()\n",
    "             .reset_index(name=\"y\")\n",
    "             .rename(columns={date_col: \"ds\"})\n",
    "             .sort_values(\"ds\")\n",
    "    )\n",
    "    \n",
    "    # Exclude last incomplete month\n",
    "    if not ts.empty:\n",
    "        last_month = ts['ds'].max()\n",
    "        ts = ts[ts['ds'] < last_month]\n",
    "    \n",
    "    # Skip if too few data points\n",
    "    if len(ts) < 24:\n",
    "        continue\n",
    "\n",
    "    # Train-test split\n",
    "    train = ts[:-6]\n",
    "    test = ts[-6:]\n",
    "    \n",
    "    # Fit Prophet\n",
    "    m = Prophet()\n",
    "    m.fit(train)\n",
    "    \n",
    "    # Make future and predict for test dates\n",
    "    future = m.make_future_dataframe(periods=6, freq=\"ME\")\n",
    "    forecast = m.predict(future)\n",
    "    forecast_test = forecast.tail(6).copy()\n",
    "    forecast_test[\"y_true\"] = test[\"y\"].values\n",
    "    \n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"])\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"]))\n",
    "    mape = np.mean(np.abs((forecast_test[\"y_true\"] - forecast_test[\"yhat\"]) / forecast_test[\"y_true\"])) * 100\n",
    "    \n",
    "    results.append({\n",
    "        \"Category\": cat,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE (%)\": mape\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(\"MAPE (%)\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e311ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:16:34.853006Z",
     "start_time": "2025-11-13T20:16:28.616601Z"
    }
   },
   "outputs": [],
   "source": [
    "category_col = \"DIVISION\" \n",
    "date_col = \"CREATED DATE\"     \n",
    "\n",
    "results = []\n",
    "\n",
    "for cat, group in df.groupby(category_col, observed=True):\n",
    "    ts = (\n",
    "        group.groupby(pd.Grouper(key=date_col, freq=\"ME\"))\n",
    "             .size()\n",
    "             .reset_index(name=\"y\")\n",
    "             .rename(columns={date_col: \"ds\"})\n",
    "             .sort_values(\"ds\")\n",
    "    )\n",
    "    \n",
    "    # Exclude last incomplete month\n",
    "    if not ts.empty:\n",
    "        last_month = ts['ds'].max()\n",
    "        ts = ts[ts['ds'] < last_month]\n",
    "    \n",
    "    # Skip if too few data points\n",
    "    if len(ts) < 24:\n",
    "        continue\n",
    "\n",
    "    # Train-test split\n",
    "    train = ts[:-6]\n",
    "    test = ts[-6:]\n",
    "    \n",
    "    # Fit Prophet\n",
    "    m = Prophet()\n",
    "    m.fit(train)\n",
    "    \n",
    "    # Make future and predict for test dates\n",
    "    future = m.make_future_dataframe(periods=6, freq=\"ME\")\n",
    "    forecast = m.predict(future)\n",
    "    forecast_test = forecast.tail(6).copy()\n",
    "    forecast_test[\"y_true\"] = test[\"y\"].values\n",
    "    \n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"])\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"]))\n",
    "    mape = np.mean(np.abs((forecast_test[\"y_true\"] - forecast_test[\"yhat\"]) / forecast_test[\"y_true\"])) * 100\n",
    "    \n",
    "    results.append({\n",
    "        \"Category\": cat,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE (%)\": mape\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(\"MAPE (%)\")\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4fafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = \"CATEGORY\" \n",
    "date_col = \"CREATED DATE\"     \n",
    "\n",
    "results = []\n",
    "\n",
    "for cat, group in df.groupby(category_col, observed=True):\n",
    "    ts = (\n",
    "        group.groupby(pd.Grouper(key=date_col, freq=\"ME\"))\n",
    "             .size()\n",
    "             .reset_index(name=\"y\")\n",
    "             .rename(columns={date_col: \"ds\"})\n",
    "             .sort_values(\"ds\")\n",
    "    )\n",
    "    \n",
    "    # Exclude last incomplete month\n",
    "    if not ts.empty:\n",
    "        last_month = ts['ds'].max()\n",
    "        ts = ts[ts['ds'] < last_month]\n",
    "    \n",
    "    # Skip if too few data points\n",
    "    if len(ts) < 24:\n",
    "        continue\n",
    "\n",
    "    # Train-test split\n",
    "    train = ts[:-6]\n",
    "    test = ts[-6:]\n",
    "    \n",
    "    # Fit Prophet\n",
    "    m = Prophet()\n",
    "    m.fit(train)\n",
    "    \n",
    "    # Make future and predict for test dates\n",
    "    future = m.make_future_dataframe(periods=6, freq=\"ME\")\n",
    "    forecast = m.predict(future)\n",
    "    forecast_test = forecast.tail(6).copy()\n",
    "    forecast_test[\"y_true\"] = test[\"y\"].values\n",
    "    \n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"])\n",
    "    rmse = np.sqrt(mean_squared_error(forecast_test[\"y_true\"], forecast_test[\"yhat\"]))\n",
    "    mape = np.mean(np.abs((forecast_test[\"y_true\"] - forecast_test[\"yhat\"]) / forecast_test[\"y_true\"])) * 100\n",
    "    \n",
    "    results.append({\n",
    "        \"Category\": cat,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE (%)\": mape\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(\"MAPE (%)\")\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = df[\"RESOLUTION_TIME_DAYS\"].quantile(0.95)\n",
    "df[\"RESOLUTION_TIME_DAYS\"] = df[\"RESOLUTION_TIME_DAYS\"].clip(upper=cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the two most recent months in your data\n",
    "latest_date = df[\"CREATED DATE\"].max()\n",
    "latest_month_start = latest_date.replace(day=1)\n",
    "second_latest_month_start = (latest_month_start - pd.DateOffset(months=1))\n",
    "\n",
    "# Keep only rows before these two months\n",
    "df_model = df[df[\"CREATED DATE\"] < second_latest_month_start].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median per case type (can contain NaN)\n",
    "medians_by_type = df_model.groupby('CASE TYPE')['RESOLUTION_TIME_DAYS'].median()\n",
    "\n",
    "# Map case-type median to rows\n",
    "df_model['MEDIAN_BY_TYPE'] = df_model['CASE TYPE'].map(medians_by_type)\n",
    "\n",
    "# Fill missing durations ONLY where case-type median exists\n",
    "df_model['RESOLUTION_TIME_DAYS'] = df_model.apply(\n",
    "    lambda row: row['MEDIAN_BY_TYPE'] if pd.isna(row['RESOLUTION_TIME_DAYS']) and not pd.isna(row['MEDIAN_BY_TYPE'])\n",
    "    else row['RESOLUTION_TIME_DAYS'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop rows where RESOLUTION_TIME_DAYS is still NaN AND the case type median was also NaN\n",
    "df_model = df_model.dropna(subset=['RESOLUTION_TIME_DAYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ed95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case volume per month\n",
    "monthly_volume = (\n",
    "    df_model\n",
    "    .groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))\n",
    "    .size()\n",
    "    .reset_index(name=\"case_volume\")\n",
    ")\n",
    "\n",
    "# Dominant case-type proportion\n",
    "case_type_monthly = (\n",
    "    df_model\n",
    "    .groupby([pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"), \"CASE TYPE\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "month_totals = case_type_monthly.groupby(\"CREATED DATE\")[\"count\"].sum()\n",
    "case_type_monthly[\"prop\"] = case_type_monthly[\"count\"] / case_type_monthly[\"CREATED DATE\"].map(month_totals)\n",
    "\n",
    "dominant_prop = (\n",
    "    case_type_monthly\n",
    "    .sort_values([\"CREATED DATE\", \"prop\"], ascending=[True, False])\n",
    "    .groupby(\"CREATED DATE\")\n",
    "    .first()\n",
    "    .reset_index()[[\"CREATED DATE\", \"prop\"]]\n",
    "    .rename(columns={\"prop\": \"dominant_case_prop\"})\n",
    ")\n",
    "\n",
    "\n",
    "# BUILD FORECASTING TS (y + regressors)\n",
    "ts = (\n",
    "    df_model\n",
    "    .groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))[\"RESOLUTION_TIME_DAYS\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"CREATED DATE\": \"ds\", \"RESOLUTION_TIME_DAYS\": \"y\"})\n",
    ")\n",
    "\n",
    "# Merge regressors\n",
    "ts = (\n",
    "    ts\n",
    "    .merge(monthly_volume.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "    .merge(dominant_prop.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    ")\n",
    "\n",
    "\n",
    "# INTERPOLATE MISSING MONTHS (critical for regressors)\n",
    "full_range = pd.date_range(ts[\"ds\"].min(), ts[\"ds\"].max(), freq=\"ME\")\n",
    "\n",
    "ts = ts.set_index(\"ds\").reindex(full_range)\n",
    "\n",
    "for col in [\"y\", \"case_volume\", \"dominant_case_prop\"]:\n",
    "    ts[col] = ts[col].interpolate().bfill().ffill()\n",
    "\n",
    "ts = ts.rename_axis(\"ds\").reset_index()\n",
    "\n",
    "\n",
    "# TRAIN/TEST SPLIT\n",
    "ts = ts[ts[\"ds\"] < pd.Timestamp(\"2025-11-01\")]\n",
    "train = ts[ts['ds'] >= '2022-01-01']\n",
    "# train = ts.iloc[:-6]\n",
    "test = ts.iloc[-6:]\n",
    "\n",
    "\n",
    "# PROPHET WITH REGRESSORS\n",
    "\n",
    "model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    changepoint_prior_scale=0.8,\n",
    ")\n",
    "\n",
    "model.add_regressor(\"case_volume\")\n",
    "model.add_regressor(\"dominant_case_prop\")\n",
    "\n",
    "model.fit(train)\n",
    "\n",
    "# Build future df with regressors\\\n",
    "future = model.make_future_dataframe(periods=12, freq=\"ME\")\n",
    "future = future.merge(ts[[\"ds\", \"case_volume\", \"dominant_case_prop\"]],\n",
    "                      on=\"ds\", how=\"left\")\n",
    "\n",
    "# Forward-fill for future months\n",
    "future[\"case_volume\"] = future[\"case_volume\"].ffill()\n",
    "future[\"dominant_case_prop\"] = future[\"dominant_case_prop\"].ffill()\n",
    "\n",
    "forecast = model.predict(future)\n",
    "\n",
    "pred = forecast[[\"ds\", \"yhat\"]].merge(test[[\"ds\", \"y\"]], on=\"ds\", how=\"inner\")\n",
    "\n",
    "mape = mean_absolute_percentage_error(pred[\"y\"], pred[\"yhat\"]) * 100\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Plot\n",
    "fig = px.line(train, x='ds', y='y', title='Resolution Time Forecast', labels={'y':'Resolution Days'})\n",
    "fig.add_scatter(x=test['ds'], y=test['y'], mode='lines+markers', name='Actual')\n",
    "\n",
    "# Plot predictions on test set (if desired)\n",
    "fig.add_scatter(x=pred['ds'], y=pred['yhat'], mode='lines', name='Forecast (Test)')\n",
    "\n",
    "# Plot future predictions\n",
    "future_forecast = forecast[forecast['ds'] > train['ds'].max()]\n",
    "fig.add_scatter(x=future_forecast['ds'], y=future_forecast['yhat'], mode='lines+markers', \n",
    "                name='Forecast (Future)', line=dict(dash='dash', color='red'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56286b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_model[\"NEIGHBORHOOD\"].unique()\n",
    "mape_results = {}\n",
    "\n",
    "for g in groups:\n",
    "    subset = df_model[df_model[\"NEIGHBORHOOD\"] == g].copy()\n",
    "    \n",
    "    # Drop rows without resolution or created dates\n",
    "    subset = subset.dropna(subset=[\"RESOLUTION_TIME_DAYS\", \"CREATED DATE\"])\n",
    "    if len(subset) < 12:  # skip tiny groups\n",
    "        continue\n",
    "    \n",
    "    # Compute regressors per group    \n",
    "    # Case volume\n",
    "    monthly_volume = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))\n",
    "        .size()\n",
    "        .reset_index(name=\"case_volume\")\n",
    "    )\n",
    "    \n",
    "    # Dominant case-type proportion\n",
    "    case_type_monthly = (\n",
    "        subset.groupby([pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"), \"CASE TYPE\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    month_totals = case_type_monthly.groupby(\"CREATED DATE\")[\"count\"].sum()\n",
    "    case_type_monthly[\"prop\"] = case_type_monthly[\"count\"] / case_type_monthly[\"CREATED DATE\"].map(month_totals)\n",
    "    dominant_prop = (\n",
    "        case_type_monthly.sort_values([\"CREATED DATE\", \"prop\"], ascending=[True, False])\n",
    "        .groupby(\"CREATED DATE\")\n",
    "        .first()\n",
    "        .reset_index()[[\"CREATED DATE\", \"prop\"]]\n",
    "        .rename(columns={\"prop\": \"dominant_case_prop\"})\n",
    "    )\n",
    "    \n",
    "    # Build time series with regressors\n",
    "    ts = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))[\"RESOLUTION_TIME_DAYS\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"CREATED DATE\": \"ds\", \"RESOLUTION_TIME_DAYS\": \"y\"})\n",
    "    )\n",
    "    \n",
    "    ts = (\n",
    "        ts\n",
    "        .merge(monthly_volume.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "        .merge(dominant_prop.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "    )\n",
    "    \n",
    "    # Interpolate missing months\n",
    "    full_range = pd.date_range(ts[\"ds\"].min(), ts[\"ds\"].max(), freq=\"ME\")\n",
    "    ts = ts.set_index(\"ds\").reindex(full_range)\n",
    "    for col in [\"y\", \"case_volume\", \"dominant_case_prop\"]:\n",
    "        ts[col] = ts[col].interpolate().bfill().ffill()\n",
    "    ts = ts.rename_axis(\"ds\").reset_index()\n",
    "    \n",
    "    # Train/test split\n",
    "    train = ts.iloc[:-6]\n",
    "    if train['y'].dropna().shape[0] < 2:\n",
    "        continue\n",
    "    test = ts.iloc[-6:]\n",
    "    \n",
    "    # Prophet with regressors\n",
    "    model = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.8)\n",
    "    model.add_regressor(\"case_volume\")\n",
    "    model.add_regressor(\"dominant_case_prop\")\n",
    "    \n",
    "    model.fit(train)\n",
    "    \n",
    "    # Build future dataframe\n",
    "    future = model.make_future_dataframe(periods=12, freq=\"ME\")\n",
    "    future = future.merge(ts[[\"ds\", \"case_volume\", \"dominant_case_prop\"]], on=\"ds\", how=\"left\")\n",
    "    future[\"case_volume\"] = future[\"case_volume\"].ffill()\n",
    "    future[\"dominant_case_prop\"] = future[\"dominant_case_prop\"].ffill()\n",
    "    \n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Evaluate\n",
    "    pred = forecast[[\"ds\", \"yhat\"]].merge(test[[\"ds\", \"y\"]], on=\"ds\", how=\"inner\")\n",
    "    mape_results[g] = mean_absolute_percentage_error(pred[\"y\"], pred[\"yhat\"]) * 100\n",
    "\n",
    "# Final MAPE table\n",
    "mape_df = pd.DataFrame.from_dict(mape_results, orient=\"index\", columns=[\"MAPE\"])\n",
    "mape_df[\"MAPE\"] = mape_df[\"MAPE\"].apply(lambda x: round(x, 2))\n",
    "mape_df.sort_values(\"MAPE\", inplace=True)\n",
    "mape_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41763837",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_model[\"DEPARTMENT\"].unique()\n",
    "mape_results = {}\n",
    "\n",
    "for g in groups:\n",
    "    subset = df_model[df_model[\"DEPARTMENT\"] == g].copy()\n",
    "    \n",
    "    # Drop rows without resolution or created dates\n",
    "    subset = subset.dropna(subset=[\"RESOLUTION_TIME_DAYS\", \"CREATED DATE\"])\n",
    "    if len(subset) < 12:  # skip tiny groups\n",
    "        continue\n",
    "    \n",
    "    # Compute regressors per group    \n",
    "    # Case volume\n",
    "    monthly_volume = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))\n",
    "        .size()\n",
    "        .reset_index(name=\"case_volume\")\n",
    "    )\n",
    "    \n",
    "    # Dominant case-type proportion\n",
    "    case_type_monthly = (\n",
    "        subset.groupby([pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"), \"CASE TYPE\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    month_totals = case_type_monthly.groupby(\"CREATED DATE\")[\"count\"].sum()\n",
    "    case_type_monthly[\"prop\"] = case_type_monthly[\"count\"] / case_type_monthly[\"CREATED DATE\"].map(month_totals)\n",
    "    dominant_prop = (\n",
    "        case_type_monthly.sort_values([\"CREATED DATE\", \"prop\"], ascending=[True, False])\n",
    "        .groupby(\"CREATED DATE\")\n",
    "        .first()\n",
    "        .reset_index()[[\"CREATED DATE\", \"prop\"]]\n",
    "        .rename(columns={\"prop\": \"dominant_case_prop\"})\n",
    "    )\n",
    "    \n",
    "    # Build time series with regressors\n",
    "    ts = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))[\"RESOLUTION_TIME_DAYS\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"CREATED DATE\": \"ds\", \"RESOLUTION_TIME_DAYS\": \"y\"})\n",
    "    )\n",
    "    \n",
    "    ts = (\n",
    "        ts\n",
    "        .merge(monthly_volume.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "        .merge(dominant_prop.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "    )\n",
    "    \n",
    "    # Interpolate missing months\n",
    "    full_range = pd.date_range(ts[\"ds\"].min(), ts[\"ds\"].max(), freq=\"ME\")\n",
    "    ts = ts.set_index(\"ds\").reindex(full_range)\n",
    "    for col in [\"y\", \"case_volume\", \"dominant_case_prop\"]:\n",
    "        ts[col] = ts[col].interpolate().bfill().ffill()\n",
    "    ts = ts.rename_axis(\"ds\").reset_index()\n",
    "    \n",
    "    # Train/test split\n",
    "    train = ts.iloc[:-6]\n",
    "    if train['y'].dropna().shape[0] < 2:\n",
    "        continue\n",
    "    test = ts.iloc[-6:]\n",
    "    \n",
    "    # Prophet with regressors\n",
    "    model = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.8)\n",
    "    model.add_regressor(\"case_volume\")\n",
    "    model.add_regressor(\"dominant_case_prop\")\n",
    "    \n",
    "    model.fit(train)\n",
    "    \n",
    "    # Build future dataframe\n",
    "    future = model.make_future_dataframe(periods=12, freq=\"ME\")\n",
    "    future = future.merge(ts[[\"ds\", \"case_volume\", \"dominant_case_prop\"]], on=\"ds\", how=\"left\")\n",
    "    future[\"case_volume\"] = future[\"case_volume\"].ffill()\n",
    "    future[\"dominant_case_prop\"] = future[\"dominant_case_prop\"].ffill()\n",
    "    \n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Evaluate\n",
    "    pred = forecast[[\"ds\", \"yhat\"]].merge(test[[\"ds\", \"y\"]], on=\"ds\", how=\"inner\")\n",
    "    mape_results[g] = mean_absolute_percentage_error(pred[\"y\"], pred[\"yhat\"]) * 100\n",
    "\n",
    "# Final MAPE table\n",
    "mape_df = pd.DataFrame.from_dict(mape_results, orient=\"index\", columns=[\"MAPE\"])\n",
    "mape_df[\"MAPE\"] = mape_df[\"MAPE\"].apply(lambda x: round(x, 2))\n",
    "mape_df.sort_values(\"MAPE\", inplace=True)\n",
    "print(mape_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a055e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_model[\"DIVISION\"].unique()\n",
    "mape_results = {}\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
    "\n",
    "for g in groups:\n",
    "    subset = df_model[df_model[\"DIVISION\"] == g].copy()\n",
    "    \n",
    "    # Drop rows without resolution or created dates\n",
    "    subset = subset.dropna(subset=[\"RESOLUTION_TIME_DAYS\", \"CREATED DATE\"])\n",
    "    if len(subset) < 12:  # skip tiny groups\n",
    "        continue\n",
    "    \n",
    "    # Compute regressors per group    \n",
    "    # Case volume\n",
    "    monthly_volume = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))\n",
    "        .size()\n",
    "        .reset_index(name=\"case_volume\")\n",
    "    )\n",
    "    \n",
    "    # Dominant case-type proportion\n",
    "    case_type_monthly = (\n",
    "        subset.groupby([pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"), \"CASE TYPE\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    month_totals = case_type_monthly.groupby(\"CREATED DATE\")[\"count\"].sum()\n",
    "    case_type_monthly[\"prop\"] = case_type_monthly[\"count\"] / case_type_monthly[\"CREATED DATE\"].map(month_totals)\n",
    "    dominant_prop = (\n",
    "        case_type_monthly.sort_values([\"CREATED DATE\", \"prop\"], ascending=[True, False])\n",
    "        .groupby(\"CREATED DATE\")\n",
    "        .first()\n",
    "        .reset_index()[[\"CREATED DATE\", \"prop\"]]\n",
    "        .rename(columns={\"prop\": \"dominant_case_prop\"})\n",
    "    )\n",
    "    \n",
    "    # Build time series with regressors\n",
    "    ts = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))[\"RESOLUTION_TIME_DAYS\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"CREATED DATE\": \"ds\", \"RESOLUTION_TIME_DAYS\": \"y\"})\n",
    "    )\n",
    "    \n",
    "    ts = (\n",
    "        ts\n",
    "        .merge(monthly_volume.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "        .merge(dominant_prop.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "    )\n",
    "    \n",
    "    # Interpolate missing months\n",
    "    full_range = pd.date_range(ts[\"ds\"].min(), ts[\"ds\"].max(), freq=\"ME\")\n",
    "    ts = ts.set_index(\"ds\").reindex(full_range)\n",
    "    for col in [\"y\", \"case_volume\", \"dominant_case_prop\"]:\n",
    "        ts[col] = ts[col].interpolate().bfill().ffill()\n",
    "    ts = ts.rename_axis(\"ds\").reset_index()\n",
    "    \n",
    "    # Train/test split\n",
    "    train = ts.iloc[:-6]\n",
    "    if train['y'].dropna().shape[0] < 2:\n",
    "        continue\n",
    "    test = ts.iloc[-6:]\n",
    "    \n",
    "    # Prophet with regressors\n",
    "    model = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.8)\n",
    "    model.add_regressor(\"case_volume\")\n",
    "    model.add_regressor(\"dominant_case_prop\")\n",
    "    \n",
    "    model.fit(train)\n",
    "    \n",
    "    # Build future dataframe\n",
    "    future = model.make_future_dataframe(periods=12, freq=\"ME\")\n",
    "    future = future.merge(ts[[\"ds\", \"case_volume\", \"dominant_case_prop\"]], on=\"ds\", how=\"left\")\n",
    "    future[\"case_volume\"] = future[\"case_volume\"].ffill()\n",
    "    future[\"dominant_case_prop\"] = future[\"dominant_case_prop\"].ffill()\n",
    "    \n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Evaluate\n",
    "    pred = forecast[[\"ds\", \"yhat\"]].merge(test[[\"ds\", \"y\"]], on=\"ds\", how=\"inner\")\n",
    "    mape_results[g] = mean_absolute_percentage_error(pred[\"y\"], pred[\"yhat\"]) * 100\n",
    "\n",
    "# Final MAPE table\n",
    "mape_df = pd.DataFrame.from_dict(mape_results, orient=\"index\", columns=[\"MAPE\"])\n",
    "mape_df[\"MAPE\"] = mape_df[\"MAPE\"].apply(lambda x: round(x, 2))\n",
    "mape_df.sort_values(\"MAPE\", inplace=True)\n",
    "mape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_model[\"CATEGORY\"].unique()\n",
    "mape_results = {}\n",
    "\n",
    "for g in groups:\n",
    "    subset = df_model[df_model[\"CATEGORY\"] == g].copy()\n",
    "    \n",
    "    # Drop rows without resolution or created dates\n",
    "    subset = subset.dropna(subset=[\"RESOLUTION_TIME_DAYS\", \"CREATED DATE\"])\n",
    "    if len(subset) < 12:  # skip tiny groups\n",
    "        continue\n",
    "    \n",
    "    # Compute regressors per group    \n",
    "    # Case volume\n",
    "    monthly_volume = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))\n",
    "        .size()\n",
    "        .reset_index(name=\"case_volume\")\n",
    "    )\n",
    "    \n",
    "    # Dominant case-type proportion\n",
    "    case_type_monthly = (\n",
    "        subset.groupby([pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"), \"CASE TYPE\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    month_totals = case_type_monthly.groupby(\"CREATED DATE\")[\"count\"].sum()\n",
    "    case_type_monthly[\"prop\"] = case_type_monthly[\"count\"] / case_type_monthly[\"CREATED DATE\"].map(month_totals)\n",
    "    dominant_prop = (\n",
    "        case_type_monthly.sort_values([\"CREATED DATE\", \"prop\"], ascending=[True, False])\n",
    "        .groupby(\"CREATED DATE\")\n",
    "        .first()\n",
    "        .reset_index()[[\"CREATED DATE\", \"prop\"]]\n",
    "        .rename(columns={\"prop\": \"dominant_case_prop\"})\n",
    "    )\n",
    "    \n",
    "    # Build time series with regressors\n",
    "    ts = (\n",
    "        subset.groupby(pd.Grouper(key=\"CREATED DATE\", freq=\"ME\"))[\"RESOLUTION_TIME_DAYS\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"CREATED DATE\": \"ds\", \"RESOLUTION_TIME_DAYS\": \"y\"})\n",
    "    )\n",
    "    \n",
    "    ts = (\n",
    "        ts\n",
    "        .merge(monthly_volume.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "        .merge(dominant_prop.rename(columns={\"CREATED DATE\": \"ds\"}), on=\"ds\", how=\"left\")\n",
    "    )\n",
    "    \n",
    "    # Interpolate missing months\n",
    "    full_range = pd.date_range(ts[\"ds\"].min(), ts[\"ds\"].max(), freq=\"ME\")\n",
    "    ts = ts.set_index(\"ds\").reindex(full_range)\n",
    "    for col in [\"y\", \"case_volume\", \"dominant_case_prop\"]:\n",
    "        ts[col] = ts[col].interpolate().bfill().ffill()\n",
    "    ts = ts.rename_axis(\"ds\").reset_index()\n",
    "    \n",
    "    # Train/test split\n",
    "    train = ts.iloc[:-6]\n",
    "    if train['y'].dropna().shape[0] < 2:\n",
    "        continue\n",
    "    test = ts.iloc[-6:]\n",
    "    \n",
    "    # Prophet with regressors\n",
    "    model = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.8)\n",
    "    model.add_regressor(\"case_volume\")\n",
    "    model.add_regressor(\"dominant_case_prop\")\n",
    "    \n",
    "    model.fit(train)\n",
    "    \n",
    "    # Build future dataframe\n",
    "    future = model.make_future_dataframe(periods=12, freq=\"ME\")\n",
    "    future = future.merge(ts[[\"ds\", \"case_volume\", \"dominant_case_prop\"]], on=\"ds\", how=\"left\")\n",
    "    future[\"case_volume\"] = future[\"case_volume\"].ffill()\n",
    "    future[\"dominant_case_prop\"] = future[\"dominant_case_prop\"].ffill()\n",
    "    \n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Evaluate\n",
    "    pred = forecast[[\"ds\", \"yhat\"]].merge(test[[\"ds\", \"y\"]], on=\"ds\", how=\"inner\")\n",
    "    mape_results[g] = mean_absolute_percentage_error(pred[\"y\"], pred[\"yhat\"]) * 100\n",
    "\n",
    "# Final MAPE table\n",
    "mape_df = pd.DataFrame.from_dict(mape_results, orient=\"index\", columns=[\"MAPE\"])\n",
    "mape_df[\"MAPE\"] = mape_df[\"MAPE\"].apply(lambda x: round(x, 2))\n",
    "mape_df.sort_values(\"MAPE\", inplace=True)\n",
    "mape_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
